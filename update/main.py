import datetime
from config1 import (
    API_KEY,
    PRELIMINARY_SEARCH_RESULTS_NUM, # For Stage 1
    DETAILED_SEARCH_RESULTS_NUM,    # For Stage 2
    SEARCH_LOG_DIR,
    DEFAULT_DEER_MODEL # Imported for logging/display purposes
)
from api_services import search_serper
from core_logic import (
    decompose_question_with_gpt,
    generate_preliminary_summary_and_questions,
    generate_report_with_gpt
)
from utils import app_logger, ensure_dir, get_session_logfile_name, append_to_session_log

def check_config():
    """Validates essential API configurations."""
    serper_api_key = API_KEY.get("SERPER_API_KEY")
    deer_api_key = API_KEY.get("DEER_API_KEY")
    deer_api_base_url = API_KEY.get("DEER_API_BASE_URL")
    serper_search_url = API_KEY.get("SERPER_SEARCH_URL")

    valid_config = True
    if not serper_api_key or len(serper_api_key) < 20:
        print("错误：请在config1.py中正确设置有效的Serper API密钥 (SERPER_API_KEY)。")
        app_logger.error("SERPER_API_KEY is missing or invalid in config1.py.")
        valid_config = False
    if not deer_api_key or deer_api_key.startswith("sk-YOUR_DEER_API_KEY") or len(deer_api_key) < 20:
        print("错误：请在config1.py中正确设置有效的DeerAPI密钥 (DEER_API_KEY)。")
        app_logger.error("DEER_API_KEY is missing, a placeholder, or invalid in config1.py.")
        valid_config = False
    if not deer_api_base_url or "YOUR_DEER_API_BASE_URL" in deer_api_base_url:
        print("错误：请在config1.py中正确设置有效的DeerAPI基础URL (DEER_API_BASE_URL)。")
        app_logger.error("DEER_API_BASE_URL is missing or a placeholder in config1.py.")
        valid_config = False
    if not serper_search_url:
        print("错误：请在config1.py中正确设置有效的Serper搜索URL (SERPER_SEARCH_URL)。")
        app_logger.error("SERPER_SEARCH_URL is missing in config1.py.")
        valid_config = False
    
    return valid_config

def format_search_results_for_llm(results):
    """Helper to format serper results into a list of snippet strings for LLM context."""
    snippets = []
    if results and isinstance(results, list): # Ensure results is a list
        for result_item in results:
            if not isinstance(result_item, dict): # Skip if item is not a dict
                app_logger.warning(f"Skipping non-dictionary item in search results: {result_item}")
                continue
            title = result_item.get('title', '无标题')
            link = result_item.get('link', '#')
            snippet_text = result_item.get('snippet', '无摘要').replace('\n', ' ').strip()
            snippets.append(f"Source Title: {title}, Link: {link}, Content Snippet: {snippet_text}")
    
    if not snippets: # If after processing, snippets list is empty
        snippets.append("未能找到相关信息。")
    return snippets

def construct_augmented_input_details(user_answers_map):
    """Constructs a string from user answers to augment Stage 2 LLM prompts."""
    if not user_answers_map or not isinstance(user_answers_map, dict):
        return "用户未提供额外的具体澄清信息。"

    details_list = []
    # These keys should match the 'id' from the questions generated by generate_preliminary_summary_and_questions
    # Ensure the question IDs used here are consistent with what generate_preliminary_summary_and_questions produces.
    if user_answers_map.get('q1_material_preference') and user_answers_map['q1_material_preference'].strip():
        details_list.append(f"- 首选材料 (Preferred Material): {user_answers_map['q1_material_preference']}")
    if user_answers_map.get('q2_key_component_model') and user_answers_map['q2_key_component_model'].strip():
        details_list.append(f"- 关键组件型号 (Key Component Model): {user_answers_map['q2_key_component_model']}")
    if user_answers_map.get('q3_critical_dimension_or_constraint') and user_answers_map['q3_critical_dimension_or_constraint'].strip():
        details_list.append(f"- 关键尺寸/约束 (Critical Dimensions/Constraints): {user_answers_map['q3_critical_dimension_or_constraint']}")
    if user_answers_map.get('q4_desired_feature_or_style') and user_answers_map['q4_desired_feature_or_style'].strip():
        details_list.append(f"- 特定功能/风格需求 (Desired Features/Style): {user_answers_map['q4_desired_feature_or_style']}")
    
    # Add any other question IDs you might have defined
    # Example: if you had a 'q5_budget_range'
    # if user_answers_map.get('q5_budget_range') and user_answers_map['q5_budget_range'].strip():
    #     details_list.append(f"- 预算范围: {user_answers_map['q5_budget_range']}")

    if not details_list:
        return "用户未提供本轮澄清问题的具体回答，或回答为空。"
    return "\n".join(details_list)

def run_assistant():
    """
    Main function to run the two-stage assistant for finding and summarizing modification solutions,
    then generating a Text-to-CAD specification.
    """
    app_logger.info("Two-Stage Solution Research Assistant run started.")
    if not check_config():
        app_logger.critical("Configuration check failed. Assistant cannot start.")
        print("请先完成config1.py中的API配置，然后重试。")
        return

    session_logfile = ""
    try:
        ensure_dir(SEARCH_LOG_DIR)
        session_logfile = get_session_logfile_name(SEARCH_LOG_DIR, prefix="session_log_2stage")
        append_to_session_log(session_logfile, f"--- Session Start (2-Stage Process): {datetime.datetime.now().isoformat()} ---")
        app_logger.info(f"Session log for this run: {session_logfile}")
        print(f"\n提示: 本次运行的详细过程将记录在文件: {session_logfile}")
    except Exception as e:
        app_logger.critical(f"Could not create or access search log directory '{SEARCH_LOG_DIR}': {e}")
        print(f"错误: 无法初始化会话日志。请检查目录 '{SEARCH_LOG_DIR}' 的权限或配置。")
        return

    try:
        # --- STAGE 1: Preliminary Research and Clarification ---
        append_to_session_log(session_logfile, "\n--- STAGE 1: Preliminary Research & Clarification ---")
        print("\n--- STAGE 1: 初步研究与需求澄清 ---")

        original_user_question = input("\n请输入您的项目初步需求 (例如“为我的无人机构建一个轻量化GPS支架”): ")
        if not original_user_question.strip():
            print("输入不能为空。程序已退出。")
            app_logger.warning("User input (original question) was empty.")
            append_to_session_log(session_logfile, "User input (original question) was empty. Session terminated.")
            return
        
        app_logger.info(f"Original User Request: '{original_user_question}'")
        append_to_session_log(session_logfile, f"Original User Request: {original_user_question}\n")

        print(f"\n[S1 P1/3] 正在分析您的问题并生成初步搜索查询 (AI Model: {DEFAULT_DEER_MODEL})...")
        sub_questions_s1 = decompose_question_with_gpt(original_user_question, stage="Stage1 Preliminary")
        
        if not sub_questions_s1:
            print("抱歉，无法为您的初步需求生成有效的搜索查询。请尝试更清晰地描述。")
            append_to_session_log(session_logfile, "Failed to decompose original question for Stage 1. Session terminated.")
            return
        
        append_to_session_log(session_logfile, "Stage 1 - Generated Preliminary Search Queries:")
        for i, sq in enumerate(sub_questions_s1): append_to_session_log(session_logfile, f"  S1 Query {i+1}: {sq}")
        append_to_session_log(session_logfile, "\n" + "="*40 + "\n")

        search_data_map_s1 = {}
        print(f"\n[S1 P2/3] 正在为初步查询执行在线搜索 (每个查询最多获取 {PRELIMINARY_SEARCH_RESULTS_NUM} 条结果)...")
        for i, sub_q in enumerate(sub_questions_s1):
            app_logger.info(f"Stage 1 Searching for query ({i+1}/{len(sub_questions_s1)}): '{sub_q}'")
            print(f"  S1 正在搜索查询 {i+1}/{len(sub_questions_s1)}: \"{sub_q}\"")
            append_to_session_log(session_logfile, f"--- Stage 1 Searching for Query: \"{sub_q}\" (Max {PRELIMINARY_SEARCH_RESULTS_NUM} results) ---")
            results = search_serper(sub_q, num_results=PRELIMINARY_SEARCH_RESULTS_NUM)
            formatted_snippets = format_search_results_for_llm(results)
            search_data_map_s1[sub_q] = formatted_snippets
            append_to_session_log(session_logfile, f"Found {len(results) if results and isinstance(results, list) else 0} raw results. Formatted Snippets for LLM:\n" + "\n".join(formatted_snippets))
            append_to_session_log(session_logfile, "---\n")
        
        print(f"\n[S1 P3/3] 正在总结初步发现并生成澄清问题 (AI Model: {DEFAULT_DEER_MODEL})...")
        summary, questions_for_user = generate_preliminary_summary_and_questions(original_user_question, search_data_map_s1)

        append_to_session_log(session_logfile, "\n--- Stage 1: Preliminary Summary & Clarifying Questions ---")
        append_to_session_log(session_logfile, f"Summary to User:\n{summary}\n")
        append_to_session_log(session_logfile, "Questions for User:")
        if questions_for_user and isinstance(questions_for_user, list):
            for q_dict in questions_for_user: append_to_session_log(session_logfile, f"  - ID: {q_dict.get('id')}, Text: {q_dict.get('text')}")
        else:
            append_to_session_log(session_logfile, "  - No valid questions were generated or an error occurred.")


        print("\n--- 初步研究摘要 ---")
        print(summary)
        
        user_answers = {}
        if not questions_for_user or not isinstance(questions_for_user, list) or not all(isinstance(q, dict) and "text" in q and "id" in q for q in questions_for_user if questions_for_user): # Check if list is not empty and items are valid
            print("\n未能生成有效的澄清问题，或问题列表为空。将尝试基于初步信息直接进入详细设计阶段。")
            app_logger.warning("No valid clarifying questions generated or list is empty. Proceeding to stage 2 with minimal user feedback.")
            augmented_user_input_details = "用户未提供本轮澄清问题的具体回答，因为问题未能有效生成。"
        else:
            print("\n--- 请回答以下问题以帮助细化您的设计需求 (若无特定偏好可直接按回车跳过) ---")
            for q_dict in questions_for_user:
                question_text = q_dict.get("text", "无效问题，请跳过。")
                question_id = q_dict.get("id", f"unknown_q_{len(user_answers)+1}")
                answer = input(f"  {question_text}\n  您的回答: ")
                user_answers[question_id] = answer.strip() # Store even if empty, construct_augmented_input_details will handle it
                append_to_session_log(session_logfile, f"User Answer for '{question_id}': {answer.strip()}")
            augmented_user_input_details = construct_augmented_input_details(user_answers)
        
        append_to_session_log(session_logfile, f"\nAugmented User Input Details for Stage 2:\n{augmented_user_input_details}\n")

        # --- STAGE 2: Detailed Research and Specification Generation ---
        append_to_session_log(session_logfile, "\n--- STAGE 2: Detailed Research & CAD Specification Generation ---")
        print("\n\n--- STAGE 2: 详细研究与设计规格生成 ---")
        
        # For Stage 2 decomposition, we use an "augmented question" to make searches more targeted.
        # However, for the final report, we pass the original_question and augmented_user_input_details separately
        # to give the LLM both the original intent and the specific clarifications.
        
        augmented_question_for_s2_decomp = original_user_question
        # Construct a more descriptive question for Stage 2 decomposition based on user answers
        s2_decomp_additions = []
        if user_answers.get('q1_material_preference') and user_answers['q1_material_preference'].strip():
            s2_decomp_additions.append(f"focusing on material '{user_answers['q1_material_preference']}'")
        if user_answers.get('q2_key_component_model') and user_answers['q2_key_component_model'].strip():
            s2_decomp_additions.append(f"for component model '{user_answers['q2_key_component_model']}'")
        if user_answers.get('q3_critical_dimension_or_constraint') and user_answers['q3_critical_dimension_or_constraint'].strip():
            s2_decomp_additions.append(f"considering constraint '{user_answers['q3_critical_dimension_or_constraint']}'")
        if user_answers.get('q4_desired_feature_or_style') and user_answers['q4_desired_feature_or_style'].strip():
             s2_decomp_additions.append(f"with feature/style '{user_answers['q4_desired_feature_or_style']}'")

        if s2_decomp_additions:
            augmented_question_for_s2_decomp += " " + " and ".join(s2_decomp_additions)
        
        append_to_session_log(session_logfile, f"Augmented question for Stage 2 decomposition: {augmented_question_for_s2_decomp}")

        print(f"\n[S2 P1/3] 基于您的反馈，正在生成更详细的搜索查询 (AI Model: {DEFAULT_DEER_MODEL})...")
        sub_questions_s2 = decompose_question_with_gpt(augmented_question_for_s2_decomp, stage="Stage2 Detailed")

        if not sub_questions_s2:
            app_logger.warning("Stage 2 decomposition failed or yielded no questions. Falling back to Stage 1 questions for detailed search if available.")
            append_to_session_log(session_logfile, "Stage 2 decomposition failed. Attempting to use Stage 1 questions for detailed search.")
            sub_questions_s2 = sub_questions_s1 
            if not sub_questions_s2:
                print("抱歉，无法为您的需求生成详细的搜索查询。无法继续。")
                append_to_session_log(session_logfile, "No valid search queries available for Stage 2. Session terminated.")
                return

        append_to_session_log(session_logfile, "Stage 2 - Generated Detailed Search Queries:")
        for i, sq in enumerate(sub_questions_s2): append_to_session_log(session_logfile, f"  S2 Query {i+1}: {sq}")
        append_to_session_log(session_logfile, "\n" + "="*40 + "\n")

        search_data_map_s2 = {}
        print(f"\n[S2 P2/3] 正在为详细查询执行在线搜索 (每个查询最多获取 {DETAILED_SEARCH_RESULTS_NUM} 条结果)...")
        for i, sub_q in enumerate(sub_questions_s2):
            app_logger.info(f"Stage 2 Searching for query ({i+1}/{len(sub_questions_s2)}): '{sub_q}'")
            print(f"  S2 正在搜索查询 {i+1}/{len(sub_questions_s2)}: \"{sub_q}\"")
            append_to_session_log(session_logfile, f"--- Stage 2 Searching for Query: \"{sub_q}\" (Max {DETAILED_SEARCH_RESULTS_NUM} results) ---")
            results = search_serper(sub_q, num_results=DETAILED_SEARCH_RESULTS_NUM)
            formatted_snippets = format_search_results_for_llm(results)
            search_data_map_s2[sub_q] = formatted_snippets
            append_to_session_log(session_logfile, f"Found {len(results) if results and isinstance(results, list) else 0} raw results. Formatted Snippets for LLM:\n" + "\n".join(formatted_snippets))
            append_to_session_log(session_logfile, "---\n")

        print(f"\n[S2 P3/3] 正在整合所有信息并生成最终的Text-to-CAD设计规格 (AI Model: {DEFAULT_DEER_MODEL})...")
        app_logger.info("Starting final Text-to-CAD specification generation.")
        append_to_session_log(session_logfile, "\n" + "="*40 + "\n--- Generating Final Text-to-CAD Specification ---")

        # Pass original_user_question for context, search_data_map_s2 for research,
        # and augmented_user_input_details for specific user choices.
        final_report = generate_report_with_gpt(original_user_question, search_data_map_s2, augmented_user_input_details)

        print("\n\n" + "="*30 + " 最终Text-to-CAD设计规格 " + "="*30)
        print(final_report)
        print("=" * (60 + len(" 最终Text-to-CAD设计规格 ") + 2)) # Adjust length to match header
        
        append_to_session_log(session_logfile, "\n--- Final Text-to-CAD Specification Output ---")
        append_to_session_log(session_logfile, final_report)
        app_logger.info("Final Text-to-CAD specification generation complete.")

    except KeyboardInterrupt:
        app_logger.warning("User interrupted the process.")
        print("\n用户已中断操作。程序已退出。")
        if session_logfile:
            append_to_session_log(session_logfile, "\n!!! USER INTERRUPTED THE PROCESS !!!")
    except Exception as e:
        app_logger.exception(f"An unexpected error occurred in run_assistant: {e}")
        print(f"发生意外错误: {e}。请检查app.log及会话日志 ({session_logfile if session_logfile else '未创建'}) 获取详细信息。")
        if session_logfile:
            append_to_session_log(session_logfile, f"\n!!! AN UNEXPECTED ERROR OCCURRED: {e} !!!")
    finally:
        if session_logfile: # Check if session_logfile was initialized before trying to write to it
            append_to_session_log(session_logfile, f"\n--- Session End (2-Stage Process): {datetime.datetime.now().isoformat()} ---")
        app_logger.info(f"Two-Stage Assistant run ended. Session log: {session_logfile if session_logfile else 'Not created due to early error'}")

if __name__ == '__main__':
    run_assistant()